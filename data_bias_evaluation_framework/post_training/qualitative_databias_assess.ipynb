{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../prepare_dataset')\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../analyze_results')\n",
    "import data_aug\n",
    "import prepare_binary_dataset\n",
    "import data_aug\n",
    "import models_classification\n",
    "import utils\n",
    "import near_duplicates\n",
    "import seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51969884",
   "metadata": {},
   "source": [
    "## Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='../../../data/eardrum_public_data'\n",
    "img_df=pd.read_csv('../metadata/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5a49d-e995-4064-9e0e-f0b5f19583e2",
   "metadata": {},
   "source": [
    "## Save embeddings\n",
    "Modify the following codes if you want to use the feature embeddings of your own model instead of the trained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c71818-979e-4c73-97a5-d311b1377247",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../experiment/vit_b_16_384_False_0.0_False_32_1234_100_True_False_0.05_0.01_0_0.9'\n",
    "param_dict=utils.read_param_file(os.path.join(save_dir,'parameters.txt'))\n",
    "model_state_name='model.pt'\n",
    "cudaID=0\n",
    "img_df['source_class']=img_df['source']+'_'+img_df['class']\n",
    "device=torch.device(f'cuda:{cudaID}')\n",
    "num_class=2\n",
    "batch_size=32\n",
    "skf = StratifiedKFold(n_splits=5, random_state=param_dict['seed'], shuffle=True)\n",
    "test_fold_id=0\n",
    "near_duplicate_set_list=[]\n",
    "for train_index, test_index in skf.split(img_df, img_df['source_class']): \n",
    "    experiment_folder=os.path.join(save_dir,str(test_fold_id))\n",
    "    train0=img_df.iloc[train_index,]\n",
    "    test=img_df.iloc[test_index,]\n",
    "    train,val=train_test_split(train0,stratify=train0['source_class'],test_size=0.2,shuffle=True,random_state=param_dict['seed'])\n",
    "    model = models_classification.model_classification(param_dict['model_name'])\n",
    "    model.cuda(cudaID)\n",
    "    model.load_state_dict(torch.load(\n",
    "        os.path.join(experiment_folder,model_state_name)\n",
    "    ))\n",
    "    train_tf,test_tf=data_aug.derive_transform(model.size,model.mean,model.std,\n",
    "                                               scale=param_dict['scale'],\n",
    "                     add_gauss_noise=param_dict['add_gauss_noise'],\n",
    "                     elastic_tf=param_dict['elastic_tf'],\n",
    "                     color_hue=param_dict['colorhue'])\n",
    "    all_data=prepare_binary_dataset.OtoDataset_Binary(img_df,transform=test_tf,\n",
    "                                                      data_dir=DATA_DIR,\n",
    "    eclipse=param_dict['eclipse'],eclipse_extent=param_dict['eclipse_extent'])\n",
    "    all_data_loader=DataLoader(all_data,batch_size=batch_size,num_workers=4,shuffle=False)\n",
    "    embedding_list=near_duplicates.return_embeddings(model,all_data_loader,device)\n",
    "    embedding_df=pd.DataFrame(embedding_list)\n",
    "    embedding_df.to_csv(f'../metadata/embedding{test_fold_id}.csv',index=False)\n",
    "    print(f'fold {test_fold_id} done')\n",
    "    test_fold_id+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dad40",
   "metadata": {},
   "source": [
    "## Near duplicate image detection on Chile dataset\n",
    "Alpha is a crucial hyperparameter. A larger alpha value would lead to the identification of more near-duplicate images. We recommend incrementally increasing the alpha value until there are images that are not immediately apparent as near-duplicates within the top 20 near-duplicate sets. We picked alpha =1.9 for the Chile dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_chile,df_chile=near_duplicates.return_near_duplicate_set_list(data_origin='Chile',img_df=img_df,alpha=1.9,merge_agressive=True)\n",
    "near_duplicates.show_top_near_duplicate_set(df_chile,img_df,DATA_DIR,top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46995428",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_chile_flatten = set([item for sublist in merged_duplicate_sets_chile for item in sublist])\n",
    "cnt_torm=len(merged_duplicate_sets_chile_flatten )-len(merged_duplicate_sets_chile)\n",
    "print(f'number of redundant images: {cnt_torm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ed963",
   "metadata": {},
   "source": [
    "### Alpha = 2.0\n",
    "By increasing alpha from 1.9 to 2.0, the algorithm is able to capture more near-duplicate images even if they have slightly different angles or field of view. However, for the second largest near-duplicate set, we were not sure whether these images were from two very different angles at the same eardrum, or they were just similar images but not near-duplicates. Thus we decided to stick with alpha = 1.9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_chile,df_chile=near_duplicates.return_near_duplicate_set_list(data_origin='Chile',img_df=img_df,alpha=2,merge_agressive=True)\n",
    "near_duplicates.show_top_near_duplicate_set(df_chile,img_df,DATA_DIR,top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69005da",
   "metadata": {},
   "source": [
    "## Near duplicate image detection on Turkey dataset\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_turkey,df_turkey=near_duplicates.return_near_duplicate_set_list(data_origin='Turkey',img_df=img_df,alpha=0.3,merge_agressive=True)\n",
    "near_duplicates.show_top_near_duplicate_set(df_turkey,img_df,DATA_DIR,top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_turkey_flatten = set([item for sublist in merged_duplicate_sets_turkey for item in sublist])\n",
    "cnt_torm=len(merged_duplicate_sets_turkey_flatten )-len(merged_duplicate_sets_turkey)\n",
    "print(f'number of redundant images: {cnt_torm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3985c82",
   "metadata": {},
   "source": [
    "## Near duplicate image detection on Ohio dataset\n",
    "alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a41f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_ohio,df_ohio=near_duplicates.return_near_duplicate_set_list(data_origin='Ohio',img_df=img_df,alpha=0.4,merge_agressive=True)\n",
    "near_duplicates.show_top_near_duplicate_set(df_ohio,img_df,DATA_DIR,top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed898759",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_duplicate_sets_ohio_flatten = set([item for sublist in merged_duplicate_sets_ohio for item in sublist])\n",
    "cnt_torm=len(merged_duplicate_sets_ohio_flatten )-len(merged_duplicate_sets_ohio)\n",
    "print(f'number of redundant images: {cnt_torm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57588b",
   "metadata": {},
   "source": [
    "## Similar-styled image detection on Ohio dataset\n",
    "alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_style_sets_ohio,df_style_ohio=near_duplicates.return_near_duplicate_set_list(data_origin='Ohio',img_df=img_df,alpha=0.9,merge_agressive=True)\n",
    "near_duplicates.show_top_near_duplicate_set(df_style_ohio,img_df,DATA_DIR,top_n=5,print_class_distribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac47697",
   "metadata": {},
   "source": [
    "### Visualize a randomly selected set of 40 examples from Style II set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb583d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "import numpy as np\n",
    "near_duplicate_set_df=df_style_ohio\n",
    "neardup_set=near_duplicate_set_df['set'].values[ii]\n",
    "neardup_set=[int(x) for x in neardup_set.split(',')]\n",
    "relative_path=img_df['relative_file_path'].values[neardup_set]\n",
    "subfolder_name=img_df['source'].values[neardup_set]\n",
    "img_paths=DATA_DIR+'/'+subfolder_name+relative_path\n",
    "sample_img_paths=np.random.choice(img_paths, size=40, replace=False)\n",
    "utils.display_image_ingrid(sample_img_paths,ncol=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d98f15",
   "metadata": {},
   "source": [
    "### Visualize a randomly selected set of 40 examples from the Style I set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=1\n",
    "import numpy as np\n",
    "near_duplicate_set_df=df_style_ohio\n",
    "neardup_set=near_duplicate_set_df['set'].values[ii]\n",
    "neardup_set=[int(x) for x in neardup_set.split(',')]\n",
    "relative_path=img_df['relative_file_path'].values[neardup_set]\n",
    "subfolder_name=img_df['source'].values[neardup_set]\n",
    "img_paths=DATA_DIR+'/'+subfolder_name+relative_path\n",
    "sample_img_paths=np.random.choice(img_paths, size=40, replace=False)\n",
    "utils.display_image_ingrid(sample_img_paths,ncol=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../prepare_dataset')\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../post_training')\n",
    "import data_aug\n",
    "import prepare_binary_dataset\n",
    "import data_aug\n",
    "import models_classification\n",
    "import utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590215e",
   "metadata": {},
   "source": [
    "### Derive features from the input image: for reproductiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "img_df=pd.read_csv('../metadata/metadata.csv')\n",
    "DATA_DIR='../../../data/eardrum_public_data'\n",
    "relative_path=img_df['relative_file_path'].values\n",
    "subfolder_name=img_df['source'].values\n",
    "img_paths=DATA_DIR+'/'+subfolder_name+relative_path\n",
    "df_feature=pd.DataFrame(columns=['hue_mean','hue_std','saturation_mean','saturation_std','value_mean','value_std'])\n",
    "for ii,save_path in enumerate(img_paths):\n",
    "    image=cv2.imread(save_path)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    features=[hsv_image[:,:,0].mean(),hsv_image[:,:,0].std(),\n",
    "    hsv_image[:,:,1].mean(),hsv_image[:,:,1].std(),\n",
    "    hsv_image[:,:,2].mean(),hsv_image[:,:,2].std()]\n",
    "    df_feature.loc[ii] =features\n",
    "img_df2=pd.concat([img_df,df_feature],axis=1)\n",
    "img_df2.to_csv('../metadata/metadata_wfeatures.csv',index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7e944",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3811fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df=pd.read_csv('../metadata/metadata_wfeatures.csv')\n",
    "seed=1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e00484",
   "metadata": {},
   "source": [
    "### Logistic regression using the HSV feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics=pd.DataFrame(columns=['train_origin','feature_type',\n",
    "                                 'val_acc', 'val_auc',\n",
    "                                 'test0_acc','test0_auc',\n",
    "                                 'test1_acc','test1_auc'])\n",
    "selected_features=['hue_mean','hue_std','saturation_mean','saturation_std','value_mean','value_std']\n",
    "for index in range(3): \n",
    "    origins=['Chile','Ohio','Turkey']\n",
    "    train_origin=origins[index]\n",
    "    print(train_origin)\n",
    "    train0=img_df[img_df.source==origins.pop(index)]\n",
    "    test0=img_df[img_df.source==origins[0]]\n",
    "    test1=img_df[img_df.source==origins[1]]\n",
    "    print('test0 test1:',origins[0],origins[1])\n",
    "    if train_origin=='Ohio':\n",
    "        train,val=train_test_split(train0,stratify=train0['class'],test_size=0.2,shuffle=True,random_state=seed)\n",
    "    else:\n",
    "        train=train0[train0.is_test==False].reset_index(drop=True)\n",
    "        val=train0[train0.is_test==True].reset_index(drop=True)\n",
    "    # train logistic regression model using 'hue_mean', 'hue_std', 'saturation_mean', 'saturation_std','value_mean', 'value_std'\n",
    "    X_train=train[selected_features]\n",
    "    y_train=train['binary_class']\n",
    "    X_val=val[selected_features]\n",
    "    y_val=val['binary_class']\n",
    "    X_test0=test0[selected_features]\n",
    "    y_test0=test0['binary_class']\n",
    "    X_test1=test1[selected_features]\n",
    "    y_test1=test1['binary_class']\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    print('coef',clf.coef_)\n",
    "    y_pred=clf.predict(X_val)\n",
    "    acc_val=metrics.accuracy_score(y_val, y_pred)\n",
    "    print('val accuracy:',acc_val)\n",
    "    auc_val=metrics.roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    print('val auc:',auc_val)\n",
    "    y_pred=clf.predict(X_test0)\n",
    "    acc_test0=metrics.accuracy_score(y_test0, y_pred)\n",
    "    auc_test0=metrics.roc_auc_score(y_test0, clf.predict_proba(X_test0)[:,1])\n",
    "    print('test0 accuracy:',acc_test0)\n",
    "    print('test0 auc:',auc_test0)\n",
    "    y_pred=clf.predict(X_test1)\n",
    "    acc_test1=metrics.accuracy_score(y_test1, y_pred)\n",
    "    auc_test1=metrics.roc_auc_score(y_test1, clf.predict_proba(X_test1)[:,1])\n",
    "    print('test1 accuracy:',acc_test1)\n",
    "    print('test1 auc:',auc_test1)\n",
    "    df_metrics.loc[index]=[train_origin,'all',acc_val,auc_val,\n",
    "                                      acc_test0,auc_test0,\n",
    "                                      acc_test1,auc_test1]\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73340202",
   "metadata": {},
   "source": [
    "### Logistic regression using the single feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef35fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics2=pd.DataFrame(columns=['train_origin','feature_type',\n",
    "                                 'val_acc', 'val_auc',\n",
    "                                 'test0_acc','test0_auc',\n",
    "                                 'test1_acc','test1_auc'])\n",
    "for index in range(3): \n",
    "    origins=['Chile','Ohio','Turkey']\n",
    "    train_origin=origins[index]\n",
    "    print(train_origin)\n",
    "    train0=img_df[img_df.source==origins.pop(index)]\n",
    "    test0=img_df[img_df.source==origins[0]]\n",
    "    test1=img_df[img_df.source==origins[1]]\n",
    "    print('test0 test1:',origins[0],origins[1])\n",
    "    if train_origin=='Ohio':\n",
    "        train,val=train_test_split(train0,stratify=train0['class'],test_size=0.2,shuffle=True,random_state=seed)\n",
    "    else:\n",
    "        train=train0[train0.is_test==False].reset_index(drop=True)\n",
    "        val=train0[train0.is_test==True].reset_index(drop=True)\n",
    "    # train logistic regression model using 'hue_mean', 'hue_std', 'saturation_mean', 'saturation_std','value_mean', 'value_std'\n",
    "    X_train=train[['saturation_std']]\n",
    "    y_train=train['binary_class']\n",
    "    X_val=val[['saturation_std']]\n",
    "    y_val=val['binary_class']\n",
    "    X_test0=test0[['saturation_std']]\n",
    "    y_test0=test0['binary_class']\n",
    "    X_test1=test1[['saturation_std']]\n",
    "    y_test1=test1['binary_class']\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_val)\n",
    "    print('coef',clf.coef_)\n",
    "    # get confidence interval of the coefficients\n",
    "\n",
    "    \n",
    "    acc_val=metrics.accuracy_score(y_val, y_pred)\n",
    "    print('val accuracy:',acc_val)\n",
    "    auc_val=metrics.roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    print('val auc:',auc_val)\n",
    "    y_pred=clf.predict(X_test0)\n",
    "    acc_test0=metrics.accuracy_score(y_test0, y_pred)\n",
    "    auc_test0=metrics.roc_auc_score(y_test0, clf.predict_proba(X_test0)[:,1])\n",
    "    print('test0 accuracy:',acc_test0)\n",
    "    print('test0 auc:',auc_test0)\n",
    "    y_pred=clf.predict(X_test1)\n",
    "    acc_test1=metrics.accuracy_score(y_test1, y_pred)\n",
    "    auc_test1=metrics.roc_auc_score(y_test1, clf.predict_proba(X_test1)[:,1])\n",
    "    print('test1 accuracy:',acc_test1)\n",
    "    print('test1 auc:',auc_test1)\n",
    "\n",
    "    df_metrics2.loc[index]=[train_origin,'saturation_std',acc_val,auc_val,\n",
    "                                      acc_test0,auc_test0,\n",
    "                                      acc_test1,auc_test1]\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af906756-0bea-412e-863d-3b01c0c76b42",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics=pd.concat([df_metrics,df_metrics2],axis=0)\n",
    "df_metrics_long=pd.melt(df_metrics, id_vars=['train_origin','feature_type'], \n",
    "value_vars=['val_acc','val_auc','test0_acc','test0_auc','test1_acc','test1_auc'\n",
    "], var_name='metrics', value_name='value')\n",
    "df_metrics_long_auc=df_metrics_long.loc[df_metrics_long['metrics'].str.contains('_auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_metrics_long_auc[df_metrics_long_auc.train_origin=='Chile'], kind=\"bar\",\n",
    "    x=\"metrics\", y=\"value\", hue='feature_type',\n",
    "    palette=\"Paired\", \n",
    "     alpha=.6, height=5\n",
    ")\n",
    "g.legend.set_title(\"Input\")\n",
    "new_labels = ['HSV feature set', 'saturation std']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "g.set_axis_labels(\"\", \"AUC\")\n",
    "g.fig.suptitle('Trained on Chile',horizontalalignment='center', verticalalignment='top')\n",
    "\n",
    "g.set_xticklabels([\"Internal\", \"Ohio\", \"Turkey\"])\n",
    "g.set(ylim=(0, 1))\n",
    "g._legend.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_metrics_long_auc[df_metrics_long_auc.train_origin=='Ohio'], kind=\"bar\",\n",
    "    x=\"metrics\", y=\"value\", hue='feature_type',\n",
    "    palette=\"Paired\", \n",
    "     alpha=.6, height=5\n",
    ")\n",
    "g.legend.set_title(\"Input\")\n",
    "new_labels = ['HSV feature set', 'saturation std']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "g.set_axis_labels(\"\", \"AUC\")\n",
    "g.fig.suptitle('Trained on Ohio')\n",
    "\n",
    "g.set_xticklabels([\"Internal\", \"Chile\", \"Turkey\"])\n",
    "g.set(ylim=(0, 1))\n",
    "g._legend.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_metrics_long_auc[df_metrics_long_auc.train_origin=='Turkey'], kind=\"bar\",\n",
    "    x=\"metrics\", y=\"value\", hue='feature_type',\n",
    "    palette=\"Paired\", \n",
    "     alpha=.6, height=5\n",
    ")\n",
    "g.legend.set_title(\"Input\")\n",
    "new_labels = ['HSV features', 'single feature']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "g.set_axis_labels(\"\", \"AUC\")\n",
    "g.fig.suptitle('Trained on Turkey')\n",
    "\n",
    "g.set_xticklabels([\"Internal\", \"Chile\", \"Ohio\"])\n",
    "g.set(ylim=(0, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drumbeat_work_env_jupyterhub]",
   "language": "python",
   "name": "conda-env-drumbeat_work_env_jupyterhub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
